services:
  selenium:
    image: selenium/standalone-chromium:latest
    container_name: selenium
    shm_size: 2g
    ports:
      - "4444:4444"
      - "7900:7900"
    environment:
      - SE_NODE_MAX_SESSIONS=1
      - SE_NODE_OVERRIDE_MAX_SESSIONS=true
      - SE_NODE_SESSION_TIMEOUT=300
      - SE_START_XVFB=true
      - SE_SCREEN_WIDTH=1920
      - SE_SCREEN_HEIGHT=1080
      - SE_SCREEN_DEPTH=24
      - OTEL_SDK_DISABLED=true
      - DISABLE_TRACING=true
    networks:
      - scraping_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4444/wd/hub/status"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "10"
        compress: "true"
    volumes:
      - ./logs/selenium:/var/log/selenium

  seekspider:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: seekspider
    depends_on:
      selenium:
        condition: service_healthy
    environment:
      - SELENIUM_HOST=selenium
      - SELENIUM_PORT=4444
      - TZ=Australia/Perth
    env_file:
      - .env
    volumes:
      - ./data:/app/data
      - ./logs/spider:/app/logs
    networks:
      - scraping_network
    logging:
      driver: "json-file"
      options:
        max-size: "200m"
        max-file: "10"
        compress: "true"

networks:
  scraping_network:
    driver: bridge